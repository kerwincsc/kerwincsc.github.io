==============================
 Mysql 常见运维问题及优化手段
==============================

- mysql 异常重启

  - 原因及解决方法

    1. 长连接累积, 可能导致内存占用过大, 被系统强行杀掉 (OOM), 从而表现为异常重启.

       - 定期断开长连接

	 使用一段时间, 或者程序里面判断执行过一个占用内存的大查询后, 断开连接,
	 之后要查询再重新连接;

       - 执行 ``mysql_reset_connection``

	 当 MySQL>=5.7, 在每次执行一个比较大的操作后.

	 此过程不需要重新做权限验证, 但是会将连接恢复到刚刚创建完时的状态

- 不要使用 **查询缓存**

  1. 查询缓存失效非常频繁

     只要有对一个表的更新, 这个表上所有的查询缓存都会被清空.

     对于更新压力大的数据库来说, **查询缓存** 的命中率非常低.

     只有当你的业务就一张静态表, 很长时间才会更新一次, 才适合用查询缓存

     Mysql8 中已经将查询缓存删掉了, 即没有这个功能了.

     - 关闭查询缓存

       将 ``query_cache_type`` 设为 **DEMAND**, 默认情况下, SQL 将不会使用查询缓存,
       而你确定要使用查询缓存的语句, 可以用 **SQL_CACHE** 显式指定

       .. code-block:: shell

	  mysql> select SQL_CACHE * from T where ID=10;x

- Oracle 迁移到 MySQL

  Oracle 数据库的默认隔离级别是 "读提交", 因此对于一些从 Oracle 迁移到 MySQL 的应用,
  为保证数据库隔离级别的一致, 一定要将 MySQL 的隔离级别设置为 "读提交"

- 搭建一些备库来增加系统的读能力

  常见的做法是用 **全量备份** 加上应用 **binlog** 来实现

- 什么时候删除 **回滚日志**

  系统会判断, 当没有事务再需要用到这些回滚日志时, 回滚日志会被删除;
  
  什么时候才不需要了呢, 就是当系统里没有比这个回滚日志更早的 read-view 的时候

- 为什么建议你尽量不要使用长事务

  **长事务** 意味着系统里面会存在很老的事务视图.
  由于这些事务随时可能访问数据库里面的任何数据, 所以这个事务提交之前,
  数据库里面它可能用到的回滚记录都必须保留, 这就会导致大量占用存储空间.

  案例:

      在 MySQL 5.5 及以前的版本, 回滚日志是跟数据字典一起放在 ibdata 文件里的,
      即使长事务最终提交, 回滚段被清理, 文件也不会变小.
      我见过数据只有 20GB, 而回滚段有 200GB 的库.
      最终只好为了清理回滚段, 重建整个库.

  除此之外, **长事务还占用锁资源**, 也可能拖垮整个库

- 长事务的产生原因

  有些客户端连接框架会默认连接成功后先执行一个 ``set autocommit=0`` 的命令.
  这就导致接下来的查询都在事务中, 如果是长连接, 就导致了意外的长事务.

- 查询长事务

  ``select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60`` 此命令用于查询持续时间超过 60s 的事务

- 如何避免长事务对业务的影响

  - 从数据库端来看

    1. 监控 ``information_schema.Innodb_trx`` 表, 设置长事务阈值, 超过就报警 / 或者 kill;

    2. Percona 的 **pt-kill** 这个工具不错, 推荐使用

    3. 在业务功能测试阶段要求输出所有的 general_log, 分析日志行为提前发现问题

    4. 如果使用的是 MySQL 5.6 或者更新版本, 把 ``innodb_undo_tablespaces`` 设置成 2
       ( 或更大的值 ). 如果真的出现大事务导致回滚段过大, 这样设置后清理起来更方便.

  - 从应用开发端看

    1. 确认是否使用了 ``set autocommit=0``.

       这个确认工作可以在测试环境中开展, 把 MySQL 的 general_log ( 查询日志 )开起来,
       然后随便跑一个业务逻辑, 通过 general_log 的日志来确认.
       一般框架如果会设置这个值, 也就会提供参数来控制行为, 你的目标就是把它改成 1.

    2. 确认是否有 **不必要的只读事务**.

       有些框架会习惯不管什么语句先用 **begin/commit** 框起来.
       我见过有些是业务并没有这个需要, 但是也把好几个 select 语句放到了事务中.
       这种 **只读事务可以去掉**.

    3. 业务连接数据库的时候, 根据业务本身的预估, 通过 ``SET MAX_EXECUTION_TIME``,
       来控制每个 **语句执行的最长时间**, 避免单个语句 **意外** 执行太长时间.
  

- 如何启动事务

  - 显式启动事务

    ``begin`` 或 ``start transaction``,配套的提交语句是 ``commit``, 回滚语句是 ``rollback``

  - ``set autocommit=0``, 将会关掉此线程的自动提交.

    意味着, 如果只执行一个 select 语句, 事务就启动了, 并且不会自动提交.

    此事务持续存在直到你主动执行 commit 或 rollback, 或者断开连接.

  建议总是使用 ``set autocommit=1``, 通过显式语句的方式来启动事务.
 
  但是有的开发同学会纠结 "多一次交互" 的问题.
  对于一个需要频繁使用事务的业务, 第二种方式每个事务在开始时都不需要主动执行一次 "begin",
  减少了语句的交互次数. 如果你也有这个顾虑, 我建议你使用 **commit work and chain** 语法.

  在 **autocommit** 为 1 的情况下, 用 **begin** 显式启动的事务,
  如果执行 **commit** 则提交事务.

  如果执行 ``commit work and chain``, 则是提交事务并自动启动下一个事务,
  这样也省去了再次执行 **begin** 语句的开销.
  同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中.

锁事
====

全局锁
------

- 如何加全局锁 ```Flush tables with read lock` (FTWRL)

- 既然要全库只读, 为什么不使用 ``set global readonly=true`` 的方式

  1. 在有些系统中，readonly的值会被用来做其他逻辑

     比如用来判断一个库是主库还是备库.
     因此, 修改 **global** 变量的方式影响面更大, 我不建议你使用

  2. 在异常处理机制上有差异

     如果执行 FTWRL 命令之后由于客户端发生异常断开, 那么 MySQL 会自动释放这个全局锁,
     整个库回到可以正常更新的状态;

     而将整个库设置为 readonly之后, 如果客户端发生异常,
     则数据库就会一直保持 readonly 状态, 这样会导致整个库长时间处于不可写状态, 风险较高.

表级锁
------
     
表锁
~~~~

**表锁** 的语法是 ``lock tables ... read/write``.

使用 ``unlock tables`` 主动释放锁, 或在客户端断开的时候自动释放.

元数据锁
~~~~~~~~

- 如何安全地给小表加字段

  首先要 **解决长事务**, 事务不提交, 就会一直占着 MDL 锁.

  在 MySQL 的 information_schema 库的 innodb_trx 表中, 你可以查到当前执行中的事务.
  如果你要做 DDL 变更的表刚好有长事务在执行, 要考虑先暂停 DDL, 或者 kill 掉这个长事务.

  但考虑一下这个场景. 如果你 **要变更的表是一个热点表**, 虽然数据量不大,
  但是上面的请求很频繁, 而你不得不加个字段, 你该怎么做呢?

  这时候 kill 可能未必管用, 因为新的请求马上就来了.

  比较理想的机制是, **在 alter table 语句里面设定等待时间**,
  如果在这个指定的等待时间里面能够拿到 MDL 写锁最好, 拿不到也不要阻塞后面的业务语句,
  **先放弃**. 之后开发人员或者 DBA 再通过重试命令重复这个过程。

  MariaDB 已经合并了 AliSQL 的这个功能,
  所以这 两个开源分支[#1]_ 目前都支持 DDL **NOWAIT/WAIT N** 这个语法.

  .. code-block:: mysql

     ALTER TABLE tbl_name NOWAIT add column ...
     ALTER TABLE tbl_name WAIT N add column ...

- 当备库用 ``--single-transaction`` 做逻辑备份的时候,
  如果从主库的 binlog 传来一个 DDL 语句会怎么样?

  假设这个DDL是针对表t1的， 这里我把备份过程中几个关键的语句列出来:

  .. code-block:: shell

     Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
     Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
     /* other tables */
     Q3:SAVEPOINT sp;
     /* 时刻 1 */
     Q4:show create table `t1`;
     /* 时刻 2 */
     Q5:SELECT * FROM `t1`;
     /* 时刻 3 */
     Q6:ROLLBACK TO SAVEPOINT sp;
     /* 时刻 4 */
     /* other tables */

     在备份开始的时候, 为了确保 RR (可重复读) 隔离级别, 再设置一次 RR 隔离级别 (Q1);

     启动事务, 这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到
     一个一致性视图 (Q2);

     设置一个保存点, 这个很重要 (Q3);

     show create 是为了拿到表结构 (Q4), 然后正式导数据 (Q5), 回滚到 SAVEPOINT sp,
     在这里的作用是释放 t1 的 MDL 锁 (Q6). 当然这部分属于 "超纲", 上文正文里面都没提到.

     DDL从主库传过来的时间按照效果不同, 我打了四个时刻.
     题目设定为小表, 我们假定到达后, 如果开始执行, 则很快能够执行完成.

  参考答案如下:

  如果在 Q4 语句执行之前到达, 现象: **没有影响**, 备份拿到的是 DDL 后的表结构.

  如果在 "时刻2" 到达, 则表结构被改过, Q5 执行的时候,
  报 **Table definition has changed, please retry transaction**, 现象: mysqldump 终止;

  如果在 "时刻2" 和 "时刻3" 之间到达, mysqldump 占着 t1 的 MDL 读锁, binlog 被阻塞,
  现象: 主从延迟, 直到 Q6 执行完成.

  从 "时刻4" 开始, mysqldump 释放了 MDL 读锁, 现象: **没有影响**,
  备份拿到的是 DDL 前的表结构.

死锁
----
     
- 当出现死锁后可采用的两种策略

  - 直接进入等待, 直到超时.

    这个超时时间可以通过参数 ``innodb_lock_wait_timeout`` 来设置

  - 发起死锁检测

    发现死锁后, 主动回滚死锁链条中的某一个事务, 让其他事务得以继续执行.
    将参数 ``innodb_deadlock_detect`` 设置为 **on**, 表示开启这个逻辑.

- 怎么解决由这种 **热点行更新** 导致的性能问题

  问题的症结在于, **死锁检测** 要耗费大量的 CPU 资源.

  - 如果你能确保这个业务一定不会出现死锁, 可以临时 **把死锁检测关掉**.

    但是这种操作本身带有一定的风险,
    因为业务设计的时候一般不会把死锁当做一个严重错误, 毕竟出现死锁了,
    就回滚, 然后通过 **业务重试** 一般就没问题了, 这是 **业务无损的**.
    而关掉死锁检测意味着可能会出现大量的超时, 这是 **业务有损的**.

  - 控制并发度

    根据上面的分析, 你会发现如果并发能够控制住,
    比如同一行同时最多只有 10 个线程在更新, 那么死锁检测的成本很低,
    就不会出现这个问题. 一个直接的想法就是, 在客户端做并发控制.

    但是, 你会很快发现这个方法不太可行, 因为客户端很多. 我见过一个应用,
    有 600 个客户端, 这样即使每个客户端控制到只有 5 个并发线程,
    汇总到数据库服务端以后, 峰值并发数也可能要达到 3000.

  - 也可以考虑通过 **将一行改成逻辑上的多行来减少锁冲突**

  因此, 这个并发控制要 **做在数据库服务端**. 如果你有中间件, **可以考虑在中间件实现**.
  如果你的团队有能修改 MySQL 源码的人, 也可以做在 MySQL 里面.

  基本思路就是, 对于相同行的更新, **在进入引擎之前排队**.
  这样在 InnoDB 内部就不会有大量的死锁检测工作了.



性能优化
========

索引
----

覆盖索引
~~~~~~~~

由于覆盖索引可以 **减少树的搜索次数**, 显著提升查询性能,
所以使用覆盖索引是一个常用的性能优化手段;

联合索引
~~~~~~~~

- 在建立联合索引的时候, 如何安排索引内的字段顺序

  1. 评估标准是, 索引的复用能力.

     因为可以支持 **最左前缀**, 所以当已经有了 (a, b) 这个联合索引后,
     一般就不需要单独在 a 上建立索引了. 因此, **第一原则是, 如果通过调整顺序,**
     **可以少维护一个索引, 那么这个顺序往往就是需要优先考虑采用的.**

  2. 如果既有联合查询, 又有基于 a, b 各自的查询呢? 查询条件里面只有 b 的语句,
     是无法使用 (a, b) 这个联合索引的, 这时候你不得不维护另外一个索引,
     也就是说你需要同时维护 (a,b), (b) 这两个索引.

     这时候，我们要考虑的原则就是 **空间** 了.

.. [#1] Mysql 应该是不支持的, 在本文完成前.
